% CREATED BY DAVID FRISK, 2014
\THETITLE\\
\TITLEDESCR\\
DANIEL EDHOLM\\
Department of Computer Science and Engineering\\
Chalmers University of Technology\\

\thispagestyle{plain}			% Supress header 
\section*{Abstract}
Emerging memory technologies aiming to bring high bandwidth memory in close proximity of the processor enables potentially lower access latency and in turn increase application performance. One approach to near memory computation is using an abstract, packet-based protocol which both allows the memory controller to be placed by the memory and for packets to be routed to adjacent memory devices. A network of memories would allow a main memory to be scalable as well as be able to add new hosts anywhere in the network. Then again, distances, and thus latency, are affected by this integration method. In this thesis we have set up a simulated network of stacked DRAM memories based on the HMC infrastructure and have measured how latency is affected by link queue contention. Furthermore, we investigate how different amounts of links between networked memory devices affect application performance. Our results indicate that without a proper governor of memory accesses, a gain in bandwidth can result in a lower performance increase than expected while increasing average latency. In addition, this behaviour becomes masked when having to traverse the network. Lastly, there is a large variance in memory request latency depending on the memory access pattern, and even when using small request sizes it is challenging to predict how applications will perform.

% KEYWORDS (MAXIMUM 10 WORDS)
\vfill
Keywords: High bandwidth memory, Hybrid memory cube, network, latency, queues, stacked memories.

\newpage				% Create empty back of side
\thispagestyle{empty}
\mbox{}